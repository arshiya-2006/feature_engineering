{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUu1d0vj-i9r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                  FEATURE ENGINEERING ASSIGNMENT  "
      ],
      "metadata": {
        "id": "QVx_f7R2HRGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) What is a Parameter?                     \n",
        "-> A Parameter is something that a machine learning model learns by itself while training, so it can make correct predictions.The more it learns, the better the parameters get, the better the model performs."
      ],
      "metadata": {
        "id": "m87SPAll-6sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) What is correlation? What does negative correlation mean?                   \n",
        "-> Correlation shows how two things are related to each other. If one increases and the other decreases → Negative correlation"
      ],
      "metadata": {
        "id": "2RxpW6hj_ZaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Define machine learning. what are the main components of machine learning?              \n",
        "-> Machine Learning is a part of Artificial Intelligence where computers learn from data and make decisions without being directly programmed.\n",
        "\n",
        "1. **Data**\n",
        "2. **Model**\n",
        "3. **Algorithm**\n",
        "4. **Training**\n",
        "5. **Prediction**\n",
        "6. **Evaluation**\n"
      ],
      "metadata": {
        "id": "NsLQYMa9AFM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) How does loss value help in determining whether the model is good or not?             \n",
        "-> The loss value tells us how wrong the model is.\n",
        "Low loss = Model is doing well\n",
        "High loss = Model is doing poorly"
      ],
      "metadata": {
        "id": "EhZ8sV8IAbTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) what are continuous and categorical variables?             \n",
        "Continuous Variables:\n",
        "These are numbers that can take any value within a range.\n",
        "Categorical Variables:\n",
        "These are variables that represent categories or groups."
      ],
      "metadata": {
        "id": "9RbCV8orBQ_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) How do we handle categorical variables in ML? what are the common techniques?          \n",
        "-> Machine Learning models can’t understand text or categories directly — they only work with numbers.\n",
        "\n",
        "So, we need to convert categorical variables into numbers before feeding them into the model.\n",
        "The most common overall technique to handle categorical variables in machine learning is **Encoding**\n",
        "Under Encoding, we mainly use:\n",
        "~Label Encoding\n",
        "~One-Hot Encoding\n",
        "~Ordinal Encoding"
      ],
      "metadata": {
        "id": "b1ugzeZJBetq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7)What do you mean by training and testing a dataset?    \n",
        "-> The training data is used to teach the model so it can learn patterns. After learning, we use the testing data to check how well the model works on new, unseen data. This helps to know if the model is good at making predictions, not just memorizing."
      ],
      "metadata": {
        "id": "iATeXHpZCZVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) What is sklearn.preprocessing?           \n",
        "-> sklearn.preprocessing is a module in Scikit-learn.\n",
        "It is used to prepare and clean the data before giving it to the model."
      ],
      "metadata": {
        "id": "BTjg3Kr3EbEZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) What is a Test set?            \n",
        "-> A test set is a part of our data that we keep aside to check how well our machine learning model performs."
      ],
      "metadata": {
        "id": "SBvdISDPEvrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) How do we split data for model fitting(training and testing) in python?\n",
        "How do you approach a machine learning problem?            \n",
        "\n",
        "->   \n",
        "\n",
        "To split data in Python, we use `train_test_split` from `sklearn.model_selection`, which divides the data into training and testing sets.\n",
        "\n",
        "To solve a machine learning problem, we understand the goal, collect and clean the data, preprocess it, split it, choose a model, train it, test it, and then improve it based on the results.\n"
      ],
      "metadata": {
        "id": "P-d8Mw7IFyEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11) Why do we have to perform EDA before fitting a model to the data?                       \n",
        "-> EDA helps to clean, understand, and prepare the data so the model can learn better and give accurate results."
      ],
      "metadata": {
        "id": "5Kz5yMcQGBsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12) How can you find correlation btw variables in python?          \n",
        "\n",
        "-> In Python, we use `.corr()` from Pandas to find the correlation between numeric variables in a dataset. It shows how strongly two variables are related, with values ranging from -1 to 1. This helps in understanding data before modeling.\n"
      ],
      "metadata": {
        "id": "-yh66H_bGa8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13) What is causation? explain the difference between correlation and causation with an example.                                       \n",
        "->Causation means that one variable directly causes a change in another. In other words, if A happens, it makes B happen. Correlation, on the other hand, only shows that two variables move together, but it doesn’t prove that one causes the other. For example, ice cream sales and drowning cases both increase in summer, so they are correlated, but eating ice cream doesn’t cause drowning. However, smoking leading to lung disease is an example of causation, because smoking directly causes harm to the lungs. So, correlation shows a relationship, but causation shows a cause-and-effect connection."
      ],
      "metadata": {
        "id": "g0Y7Ao-sG3vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14) What is an optimizer? What are different types of optimizers? Explain each with an example.                                    \n",
        "->An optimizer is an algorithm that updates a model’s parameters to reduce error and improve predictions. Common optimizers include:\n",
        "\n",
        "~Gradient Descent: updates using the whole dataset.\n",
        "\n",
        "~SGD (Stochastic Gradient Descent): updates on small batches for faster training.\n",
        "\n",
        "~Momentum: speeds up learning by adding past updates.\n",
        "\n",
        "~AdaGrad: adapts learning rate for each parameter.\n",
        "\n",
        "~RMSProp: controls learning rate with moving averages.\n",
        "\n",
        "~Adam: combines Momentum and RMSProp for fast, stable learning."
      ],
      "metadata": {
        "id": "aHbqIX4nZrGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15) What is sklearn.linear_model()?                                  \n",
        "->sklearn.linear_model is a module in Scikit-learn (the popular Python ML library) that contains linear models for regression and classification tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "AoDXlde9aizh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16) What does model.fit() do? What arguments must be given?             \n",
        "->The `model.fit()` function is used to train a machine learning model by allowing it to learn patterns from the data. It takes two main arguments: `X_train`, which contains the input features, and `y_train`, which has the target values or labels we want the model to predict. By giving these to `model.fit()`, we teach the model the relationship between the inputs and outputs so it can make accurate predictions on new data. This step is essential because it’s where the model learns from the training data.\n"
      ],
      "metadata": {
        "id": "JSelzA1Iat2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17)What does model.predict() do? What arguments must be given?                 \n",
        "->`model.predict()` uses a trained model to make predictions on new data. It takes one argument: the input features (e.g., `X_test`) and returns the predicted values.\n"
      ],
      "metadata": {
        "id": "FXQoacZebopw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18)What is feature scaling? How does it help in machine learning?                       \n",
        "->**Feature scaling** is the process of **adjusting the range of numeric features** so they’re on a similar scale.\n",
        "\n",
        "It helps in machine learning because many models work better and converge faster when features have similar scales. Without scaling, features with larger values can dominate the learning process, leading to poor model performance.\n"
      ],
      "metadata": {
        "id": "Dons3CJacCQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19)How do we perform scaling in Python?                  \n",
        "->We perform scaling in Python using tools like `StandardScaler` or `MinMaxScaler` from `sklearn.preprocessing`. First, we create a scaler object, then use `fit_transform()` on the data to scale the features. This ensures all features are on a similar range, which helps machine learning models learn better and faster.\n"
      ],
      "metadata": {
        "id": "FsCGMkV7clvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20) Explain data encoding?                 \n",
        "->**Data encoding** converts categorical data into numbers so machine learning models can understand it. Common methods are **Label Encoding** and **One-Hot Encoding**.\n"
      ],
      "metadata": {
        "id": "XbDBm5bCdJIG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9z6mm4U9atEN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}